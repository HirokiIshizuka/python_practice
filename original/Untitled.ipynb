{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MeCab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a1812c12fc0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mMeCab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCaboCha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mJpParser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MeCab'"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "import CaboCha\n",
    "from collections import namedtuple\n",
    "\n",
    "class JpParser:\n",
    "  \"\"\"\n",
    "  return parsed data with Mecab\n",
    "  \"\"\"\n",
    "  POS_DIC = {\n",
    "    'BOS/EOS': 'EOS', # end of sentense\n",
    "    '形容詞' : 'ADJ',\n",
    "    '副詞'   : 'ADV',\n",
    "    '名詞'   : 'NOUN',\n",
    "    '動詞'   : 'VERB',\n",
    "    '助動詞' : 'AUX',\n",
    "    '助詞'   : 'PART',\n",
    "    '連体詞' : 'ADJ', # Japanese-specific POS\n",
    "    '感動詞' : 'INTJ',\n",
    "    '接続詞' : 'CONJ',\n",
    "    '*'      : 'X',\n",
    "  }\n",
    "\n",
    "  def __init__(self, * ,sys_dic_path=''):\n",
    "    opt_m = \"-Ochasen\"\n",
    "    opt_c = '-f4'\n",
    "    if sys_dic_path:\n",
    "      opt_m += ' -d {0}'.format(sys_dic_path)\n",
    "      opt_c += ' -d {0}'.format(sys_dic_path)\n",
    "    tagger = MeCab.Tagger(opt_m)\n",
    "    tagger.parse('') # for UnicodeDecodeError\n",
    "    self._tagger = tagger\n",
    "    self._parser = CaboCha.Parser(opt_c)\n",
    "\n",
    "  def get_sentences(self, text):\n",
    "    \"\"\" \n",
    "    input: text have many sentences\n",
    "    output: ary of sentences ['sent1', 'sent2', ...]\n",
    "    \"\"\"\n",
    "    EOS_DIC = ['。', '．', '！','？','!?', '!', '?' ]\n",
    "    sentences = list()\n",
    "    sent = ''\n",
    "    for token in self.tokenize(text):\n",
    "      # print(token.pos_jp, token.pos, token.surface, sent)\n",
    "      # TODO: this is simple way. ex)「今日は雨ね。」と母がいった\n",
    "      sent += token.surface\n",
    "      if token.surface in EOS_DIC and sent != '':\n",
    "        sentences.append(sent)\n",
    "        sent = ''\n",
    "    return sentences\n",
    "\n",
    "\n",
    "  def tokenize(self, sent):\n",
    "    node = self._tagger.parseToNode( sent )\n",
    "    tokens = list()\n",
    "    idx = 0\n",
    "    while node:\n",
    "      feature = node.feature.split(',')\n",
    "      token = namedtuple('Token', 'idx, surface, pos, pos_detail1, pos_detail2, pos_detail3,\\\n",
    "                          infl_type, infl_form, base_form, reading, phonetic')\n",
    "      token.idx         = idx\n",
    "      token.surface     = node.surface  # 表層形\n",
    "      token.pos_jp      = feature[0]    # 品詞\n",
    "      token.pos_detail1 = feature[1]    # 品詞細分類1\n",
    "      token.pos_detail2 = feature[2]    # 品詞細分類2\n",
    "      token.pos_detail3 = feature[3]    # 品詞細分類3\n",
    "      token.infl_type   = feature[4]    # 活用型\n",
    "      token.infl_form   = feature[5]    # 活用形\n",
    "      token.base_form   = feature[6]    # 原型\n",
    "      token.pos         = self.POS_DIC.get( feature[0], 'X' )     # 品詞\n",
    "      token.reading     = feature[7] if len(feature) > 7 else ''  # 読み\n",
    "      token.phonetic    = feature[8] if len(feature) > 8 else ''  # 発音\n",
    "      #\n",
    "      tokens.append(token)\n",
    "      idx += 1\n",
    "      node = node.next\n",
    "    return tokens\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  jp = JpParser( sys_dic_path='/usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "  # Japanese famous poem written by Soseki natusme.\n",
    "  sentences = jp.get_sentences('我輩は猫である。名前はまだ無い。どこで生れたかとんと見当けんとうがつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。')\n",
    "  for sent in sentences:\n",
    "    # token --------------------------------------\n",
    "    sent_data = jp.tokenize(sent)\n",
    "    for s in sent_data:\n",
    "      print(s.surface, s.base_form, s.pos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
